{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U tensorflow-serving-api==1.15.* --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = 'news-ml-257304'\n",
    "BUCKET = 'news-ml'\n",
    "ROOT = 'mlpipeline'\n",
    "MODEL_DIR = os.path.join(ROOT,'models').replace(\"\\\\\",\"/\")\n",
    "PACKAGES_DIR = os.path.join(ROOT,'packages').replace(\"\\\\\",\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!gcloud config set project {PROJECT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!gsutil rm -r gs://{BUCKET}/{ROOT}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_mapping = {\n",
    "    0: 'negative',\n",
    "    2: 'neutral',\n",
    "    4: 'positive'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data can be downloaded from: https://www.kaggle.com/kazanova/sentiment140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df_twitter = pd.read_csv('training.csv', encoding='latin1', header=None)\\\n",
    "             .rename(columns={\n",
    "                 0: 'sentiment',\n",
    "                 1: 'id',\n",
    "                 2: 'posted_at',\n",
    "                 3: 'query',\n",
    "                 4: 'username',\n",
    "                 5: 'text'\n",
    "             })[['sentiment', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter[\"sentiment_label\"] = df_twitter[\"sentiment\"].map(sentiment_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter[\"sentiment_label\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Data processing fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%writefile preprocess.py\n",
    "\n",
    "from tensorflow.python.keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing import text\n",
    "import re\n",
    "\n",
    "\n",
    "class TextPreprocessor(object):\n",
    "    def __init__(self, vocab_size, max_sequence_length):\n",
    "        self._vocab_size = vocab_size\n",
    "        self._max_sequence_length = max_sequence_length\n",
    "        self._tokenizer = None\n",
    "\n",
    "    def _clean_line(self, text):\n",
    "        text = re.sub(r\"http\\S+\", \"\", text)\n",
    "        text = re.sub(r\"@[A-Za-z0-9]+\", \"\", text)\n",
    "        text = re.sub(r\"#[A-Za-z0-9]+\", \"\", text)\n",
    "        text = text.replace(\"RT\",\"\")\n",
    "        text = text.lower()\n",
    "        text = text.strip()\n",
    "        return text\n",
    "    \n",
    "    def fit(self, text_list):        \n",
    "        # Create vocabulary from input corpus.\n",
    "        text_list_cleaned = [self._clean_line(txt) for txt in text_list]\n",
    "        tokenizer = text.Tokenizer(num_words=self._vocab_size)\n",
    "        tokenizer.fit_on_texts(text_list)\n",
    "        self._tokenizer = tokenizer\n",
    "\n",
    "    def transform(self, text_list):        \n",
    "        # Transform text to sequence of integers\n",
    "        text_list = [self._clean_line(txt) for txt in text_list]\n",
    "        text_sequence = self._tokenizer.texts_to_sequences(text_list)\n",
    "\n",
    "        # Fix sequence length to max value. Sequences shorter than the length are\n",
    "        # padded in the beginning and sequences longer are truncated\n",
    "        # at the beginning.\n",
    "        padded_text_sequence = sequence.pad_sequences(\n",
    "          text_sequence, maxlen=self._max_sequence_length)\n",
    "        return padded_text_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some small test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from preprocess import TextPreprocessor\n",
    "\n",
    "processor = TextPreprocessor(5, 5)\n",
    "processor.fit(['hello machine learning','test'])\n",
    "processor.transform(['hello machine learning',\"lol\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = {'negative': 0, 'positive': 1}  # label-to-int mapping\n",
    "VOCAB_SIZE = 25000  # Limit on the number vocabulary size used for tokenization\n",
    "MAX_SEQUENCE_LENGTH = 50  # Sentences will be truncated/padded to this length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from preprocess import TextPreprocessor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sents = df_twitter.text\n",
    "labels = np.array(df_twitter.sentiment_label.map(CLASSES))\n",
    "\n",
    "# Train and test split\n",
    "X, _, y, _ = train_test_split(sents, labels, test_size=0.1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "# Create vocabulary from training corpus.\n",
    "processor = TextPreprocessor(VOCAB_SIZE, MAX_SEQUENCE_LENGTH)\n",
    "processor.fit(X_train)\n",
    "\n",
    "# Preprocess the data\n",
    "train_texts_vectorized = processor.transform(X_train)\n",
    "eval_texts_vectorized = processor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./processor_state.pkl', 'wb') as f:\n",
    "    pickle.dump(processor, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "LEARNING_RATE = .001\n",
    "EMBEDDING_DIM = 50\n",
    "FILTERS = 64\n",
    "DROPOUT_RATE = 0.5\n",
    "POOL_SIZE = 3\n",
    "NUM_EPOCH = 25\n",
    "BATCH_SIZE = 128\n",
    "KERNEL_SIZES = [2, 5, 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Basic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def create_model(vocab_size, embedding_dim, filters, kernel_sizes, dropout_rate, pool_size, embedding_matrix):\n",
    "    \n",
    "    # Input layer\n",
    "    model_input = tf.keras.layers.Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "\n",
    "    # Embedding layer\n",
    "    z = tf.keras.layers.Embedding(\n",
    "        input_dim=vocab_size + 1,\n",
    "        output_dim=embedding_dim,\n",
    "        input_length=MAX_SEQUENCE_LENGTH,\n",
    "        weights=[embedding_matrix]\n",
    "    )(model_input)\n",
    "\n",
    "    z = tf.keras.layers.Dropout(dropout_rate)(z)\n",
    "\n",
    "    # Convolutional block\n",
    "    conv_blocks = []\n",
    "    for kernel_size in kernel_sizes:\n",
    "        conv = tf.keras.layers.Convolution1D(\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=\"valid\",\n",
    "            activation=\"relu\",\n",
    "            bias_initializer='random_uniform',\n",
    "            strides=1)(z)\n",
    "        conv = tf.keras.layers.MaxPooling1D(pool_size=2)(conv)\n",
    "        conv = tf.keras.layers.Flatten()(conv)\n",
    "        conv_blocks.append(conv)\n",
    "        \n",
    "    z = tf.keras.layers.Concatenate()(conv_blocks) if len(conv_blocks) > 1 else conv_blocks[0]\n",
    "\n",
    "    z = tf.keras.layers.Dropout(dropout_rate)(z)\n",
    "    z = tf.keras.layers.Dense(100, activation=\"relu\")(z)\n",
    "    model_output = tf.keras.layers.Dense(1, activation=\"sigmoid\")(z)\n",
    "    model = tf.keras.models.Model(model_input, model_output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Pretrained Glove embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding can be downloaded here: https://nlp.stanford.edu/projects/glove/\n",
    "- Download file [here](http://nlp.stanford.edu/data/glove.twitter.27B.zip)\n",
    "- Twitter (2B tweets, 27B tokens, 1.2M vocab, uncased, 25d, 50d, 100d, & 200d vectors, 1.42 GB download)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coefs(word, *arr): \n",
    "    return word, np.asarray(arr, dtype='float32')\n",
    "\n",
    "embeddings_index = dict(get_coefs(*o.strip().split()) for o in open('glove.twitter.27B.50d.txt','r', encoding='utf8'))                                                                                                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "word_index = processor._tokenizer.word_index\n",
    "nb_words = min(VOCAB_SIZE, len(word_index))\n",
    "embedding_matrix = np.zeros((nb_words + 1, EMBEDDING_DIM))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i >= VOCAB_SIZE: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Create, compile and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model = create_model(VOCAB_SIZE, EMBEDDING_DIM, FILTERS, KERNEL_SIZES, DROPOUT_RATE,POOL_SIZE, embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model with learning parameters.\n",
    "\n",
    "optimizer = tf.keras.optimizers.Nadam(lr=0.001)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#Keras train\n",
    "history = model.fit(\n",
    "    train_texts_vectorized, \n",
    "    y_train, \n",
    "    epochs=NUM_EPOCH, \n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(eval_texts_vectorized, y_test),\n",
    "    verbose=2,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_acc',\n",
    "            min_delta=0.005,\n",
    "            patience=3,\n",
    "            factor=0.5),\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            min_delta=0.005, \n",
    "            patience=5, \n",
    "            verbose=0, \n",
    "            mode='auto'\n",
    "        ),\n",
    "        tf.keras.callbacks.History()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"history.pkl\",'wb') as file:\n",
    "    pickle.dump(history.history,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('keras_saved_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Prepare custom model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%writefile model_prediction.py\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class CustomModelPrediction(object):\n",
    "\n",
    "  def __init__(self, model, processor):\n",
    "    self._model = model\n",
    "    self._processor = processor\n",
    "\n",
    "  def _postprocess(self, predictions):\n",
    "    labels = ['negative', 'positive']\n",
    "    return [\n",
    "        {\n",
    "            \"label\":labels[int(np.round(prediction))],\n",
    "            \"score\":float(np.round(prediction,4))\n",
    "        } for prediction in predictions]\n",
    "\n",
    "\n",
    "  def predict(self, instances, **kwargs):\n",
    "    preprocessed_data = self._processor.transform(instances)\n",
    "    predictions =  self._model.predict(preprocessed_data)\n",
    "    labels = self._postprocess(predictions)\n",
    "    return labels\n",
    "\n",
    "\n",
    "  @classmethod\n",
    "  def from_path(cls, model_dir):\n",
    "    import tensorflow.keras as keras\n",
    "    model = keras.models.load_model(\n",
    "      os.path.join(model_dir,'keras_saved_model.h5'))\n",
    "    with open(os.path.join(model_dir, 'processor_state.pkl'), 'rb') as f:\n",
    "      processor = pickle.load(f)\n",
    "\n",
    "    return cls(model, processor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requests = ([\"God I hate the north\", \"god I love this\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from model_prediction import CustomModelPrediction\n",
    "\n",
    "classifier = CustomModelPrediction.from_path('.')\n",
    "results = classifier.predict(requests)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Package it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%writefile setup.py\n",
    "\n",
    "from setuptools import setup\n",
    "\n",
    "setup(\n",
    "  name=\"tweet_sentiment_classifier\",\n",
    "  version=\"0.1\",\n",
    "  include_package_data=True,\n",
    "  scripts=[\"preprocess.py\", \"model_prediction.py\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrap it up and copy to GCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!python setup.py sdist\n",
    "!gsutil cp ./dist/tweet_sentiment_classifier-0.1.tar.gz gs://{BUCKET}/{PACKAGES_DIR}/tweet_sentiment_classifier-0.1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!gsutil cp keras_saved_model.h5 gs://{BUCKET}/{MODEL_DIR}/\n",
    "!gsutil cp processor_state.pkl gs://{BUCKET}/{MODEL_DIR}/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create model and version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME='twitter_model'\n",
    "VERSION_NAME='v1'\n",
    "RUNTIME_VERSION='1.15'\n",
    "REGION='us-central1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!gcloud ai-platform models create {MODEL_NAME} --regions {REGION}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!gcloud ai-platform versions delete {VERSION_NAME} --model {MODEL_NAME} --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!gcloud beta ai-platform versions create {VERSION_NAME} \\\n",
    "--model {MODEL_NAME} \\\n",
    "--origin gs://{BUCKET}/{MODEL_DIR} \\\n",
    "--python-version 3.5 \\\n",
    "--runtime-version {RUNTIME_VERSION} \\\n",
    "--package-uris gs://{BUCKET}/{PACKAGES_DIR}/tweet_sentiment_classifier-0.1.tar.gz \\\n",
    "--prediction-class=model_prediction.CustomModelPrediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient import discovery\n",
    "from oauth2client.client import GoogleCredentials\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requests = [\n",
    "    \"god this episode sucks\",\n",
    "    \"meh, I kinda like it\",\n",
    "    \"what were the writer thinking, omg!\",\n",
    "    \"omg! what a twist, who would'v though :o!\",\n",
    "    \"woohoow, sansa for the win!\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON format the requests\n",
    "request_data = {'instances': requests}\n",
    "\n",
    "# Authenticate and call CMLE prediction API \n",
    "#credentials = GoogleCredentials.get_application_default()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "api = discovery.build(\n",
    "  'ml', 'v1',\n",
    "  discoveryServiceUrl='https://storage.googleapis.com/cloud-ml/discovery/ml_v1_discovery.json')\n",
    "\n",
    "parent = 'projects/{}/models/{}/versions/{}'.format(PROJECT, MODEL_NAME, VERSION_NAME)\n",
    "parent = 'projects/{}/models/{}'.format(PROJECT, MODEL_NAME)\n",
    "response = api.projects().predict(body=request_data, name=parent).execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "response[\"predictions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
